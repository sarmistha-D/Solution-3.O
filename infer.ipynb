{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import torch\n",
    "from torch import nn\n",
    "from utils import *\n",
    "from sklearn.metrics import *\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_data.pkl\", \"rb\") as f:\n",
    "    test_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "evs_path = 'weights/evs_model.pth'\n",
    "main_model_path = \"weights/main_model.pth\"\n",
    "\n",
    "\n",
    "evs = torch.load(evs_path, map_location=device)\n",
    "main_model = torch.load(main_model_path, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Evaluate:\n",
    "    def __init__(\n",
    "        self,\n",
    "        main_model,\n",
    "        evs_model,\n",
    "        device,\n",
    "        loss_function,\n",
    "        multi_model=False,\n",
    "        batch_size=12,\n",
    "    ):\n",
    "        self.main_model = main_model.eval()\n",
    "        self.evs_model = evs_model.eval()\n",
    "        self.device = device\n",
    "        self.multi_model = multi_model\n",
    "        self.loss = loss_function\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def eval(self, dataset):\n",
    "        batch_size = self.batch_size\n",
    "        real = []\n",
    "        pred = []\n",
    "        y_scores = []\n",
    "        video_ids = []\n",
    "        losses = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(dataset), batch_size):\n",
    "                batch = [x[0] for x in dataset[i : i + batch_size]]\n",
    "                labels = torch.stack([x[1] for x in dataset[i : i + batch_size]])\n",
    "                video_ids.append([x[-1] for x in dataset[i : i + batch_size]])\n",
    "                audio_data = [torch.stack([y[1] for y in x]).squeeze(1) for x in batch]\n",
    "                video_data = [[y[0] for y in x] for x in batch]\n",
    "                video_data = [\n",
    "                    [torch.stack(y).squeeze(1) if type(y) is list else y for y in x]\n",
    "                    for x in video_data\n",
    "                ]\n",
    "                video_data = [\n",
    "                    self.evs_model(*pad(x, self.evs_model, device=self.device))\n",
    "                    for x in video_data\n",
    "                ]\n",
    "                video_data, v_mask = pad(\n",
    "                    video_data, self.main_model, device=self.device\n",
    "                )\n",
    "                audio_data, a_mask = pad(\n",
    "                    audio_data, self.main_model, device=self.device\n",
    "                )\n",
    "                if self.multi_model:\n",
    "                    final_data = audio_data + video_data\n",
    "                else:\n",
    "                    final_data = audio_data\n",
    "                label_output = self.main_model(final_data, attention_mask=a_mask)\n",
    "                losses.append(\n",
    "                    self.loss(label_output.view(-1, 3), labels.to(self.device).view(-1))\n",
    "                )\n",
    "                \n",
    "                # Store raw model outputs (probabilities)\n",
    "                y_scores.append(F.softmax(label_output.view(-1, 5, 3),dim=-1))#label_output.view(-1, 5, 3)\n",
    "                \n",
    "                pred.append(torch.argmax(label_output.view(-1, 5, 3), dim=-1))\n",
    "                real.append(labels)\n",
    "                \n",
    "        \n",
    "        real, pred = torch.cat(real).cpu(), torch.cat(pred).cpu() \n",
    "        y_scores = torch.cat(y_scores).cpu()  # Concatenate all y_scores\n",
    "        y_scores_aspects = y_scores[:, :, 1:].max(dim=-1).values.numpy()\n",
    "        y_scores_complaint = y_scores[:, :, 2:].max(dim=-1).values.numpy()\n",
    "        \n",
    "        return (\n",
    "            f1_score(real >= 1, pred >= 1, average=\"micro\"),\n",
    "            f1_score(real >= 2, pred >= 2, average=\"micro\"),\n",
    "            torch.mean(torch.stack(losses)).item(),\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"Video ID\": [y for x in video_ids for y in x],\n",
    "                    \"Aspects real\": (real >= 1).to(torch.long).tolist(),\n",
    "                    \"Aspects pred\": (pred >= 1).to(torch.long).tolist(),\n",
    "                    \"Complaint real\": (real >= 2).to(torch.long).tolist(),\n",
    "                    \"Complaint pred\": (pred >= 2).to(torch.long).tolist(),\n",
    "                }\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6025641025641025"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator  = Evaluate(\n",
    "    main_model, evs_model=evs, device=device, loss_function=loss_fn, multi_model=True\n",
    ")\n",
    "f1_aspect, f1_complaint, loss_cal, data= evaluator.eval(test_dataset)\n",
    "f1_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video ID</th>\n",
       "      <th>Aspects real</th>\n",
       "      <th>Aspects pred</th>\n",
       "      <th>Complaint real</th>\n",
       "      <th>Complaint pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51e4YIHE5sU.mp4</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FI65fJQ6bEM.mp4</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1705732629717258718.mp4</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>[1, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1705745405131051310.mp4</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yrgnxaAOuws.mp4</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>k4gZTf2LVdU.mp4</td>\n",
       "      <td>[1, 0, 1, 1, 0]</td>\n",
       "      <td>[0, 0, 1, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>J8-pMPud7gE.mp4</td>\n",
       "      <td>[0, 1, 1, 1, 0]</td>\n",
       "      <td>[0, 0, 1, 1, 0]</td>\n",
       "      <td>[0, 1, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>b6PolFcMVpI.mp4</td>\n",
       "      <td>[0, 0, 1, 1, 1]</td>\n",
       "      <td>[0, 0, 1, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1468611338192797702.mp4</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>lasAAAhkFb0.mp4</td>\n",
       "      <td>[1, 0, 1, 1, 0]</td>\n",
       "      <td>[1, 0, 1, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Video ID     Aspects real     Aspects pred  \\\n",
       "0           51e4YIHE5sU.mp4  [0, 1, 0, 0, 0]  [0, 0, 0, 1, 0]   \n",
       "1           FI65fJQ6bEM.mp4  [0, 0, 0, 1, 0]  [0, 0, 0, 1, 0]   \n",
       "2   1705732629717258718.mp4  [0, 0, 0, 0, 1]  [1, 0, 0, 1, 0]   \n",
       "3   1705745405131051310.mp4  [0, 0, 0, 1, 0]  [0, 0, 0, 0, 0]   \n",
       "4           yrgnxaAOuws.mp4  [0, 1, 0, 0, 0]  [0, 0, 0, 0, 0]   \n",
       "..                      ...              ...              ...   \n",
       "59          k4gZTf2LVdU.mp4  [1, 0, 1, 1, 0]  [0, 0, 1, 1, 0]   \n",
       "60          J8-pMPud7gE.mp4  [0, 1, 1, 1, 0]  [0, 0, 1, 1, 0]   \n",
       "61          b6PolFcMVpI.mp4  [0, 0, 1, 1, 1]  [0, 0, 1, 1, 0]   \n",
       "62  1468611338192797702.mp4  [0, 0, 0, 0, 1]  [0, 0, 0, 0, 1]   \n",
       "63          lasAAAhkFb0.mp4  [1, 0, 1, 1, 0]  [1, 0, 1, 1, 0]   \n",
       "\n",
       "     Complaint real   Complaint pred  \n",
       "0   [0, 0, 0, 0, 0]  [0, 0, 0, 0, 0]  \n",
       "1   [0, 0, 0, 1, 0]  [0, 0, 0, 0, 0]  \n",
       "2   [0, 0, 0, 0, 1]  [0, 0, 0, 0, 0]  \n",
       "3   [0, 0, 0, 0, 0]  [0, 0, 0, 0, 0]  \n",
       "4   [0, 1, 0, 0, 0]  [0, 0, 0, 0, 0]  \n",
       "..              ...              ...  \n",
       "59  [0, 0, 0, 0, 0]  [0, 0, 0, 0, 0]  \n",
       "60  [0, 1, 0, 1, 0]  [0, 0, 0, 0, 0]  \n",
       "61  [0, 0, 0, 1, 0]  [0, 0, 0, 0, 0]  \n",
       "62  [0, 0, 0, 0, 1]  [0, 0, 0, 0, 1]  \n",
       "63  [0, 0, 0, 0, 0]  [0, 0, 0, 0, 0]  \n",
       "\n",
       "[64 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Video ID', 'Aspects real_1', 'Aspects real_2', 'Aspects real_3',\n",
       "       'Aspects real_4', 'Aspects real_5', 'Aspects pred_1', 'Aspects pred_2',\n",
       "       'Aspects pred_3', 'Aspects pred_4', 'Aspects pred_5',\n",
       "       'Complaint real_1', 'Complaint real_2', 'Complaint real_3',\n",
       "       'Complaint real_4', 'Complaint real_5', 'Complaint pred_1',\n",
       "       'Complaint pred_2', 'Complaint pred_3', 'Complaint pred_4',\n",
       "       'Complaint pred_5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    if isinstance(df[col][0], list):  # Check if column contains lists (one-hot encoded arrays)\n",
    "        expanded_array = np.array(df[col].tolist())\n",
    "        num_categories = expanded_array.shape[1]\n",
    "        category_columns = [f'{col}_{i+1}' for i in range(num_categories)]\n",
    "        df[category_columns] = pd.DataFrame(expanded_array, index=df.index)\n",
    "        df.drop(columns=[col], inplace=True)  \n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics Results for Aspects:\n",
      "Aspect_1:\n",
      "\tHamming Loss: 0.234375\n",
      "\tAccuracy: 0.765625\n",
      "\tMicro-F1 Score: 0.765625\n",
      "\tMacro-F1 Score: 0.5727636849132176\n",
      "Aspect_2:\n",
      "\tHamming Loss: 0.1875\n",
      "\tAccuracy: 0.8125\n",
      "\tMicro-F1 Score: 0.8125\n",
      "\tMacro-F1 Score: 0.518796992481203\n",
      "Aspect_3:\n",
      "\tHamming Loss: 0.078125\n",
      "\tAccuracy: 0.921875\n",
      "\tMicro-F1 Score: 0.921875\n",
      "\tMacro-F1 Score: 0.8885405781957506\n",
      "Aspect_4:\n",
      "\tHamming Loss: 0.28125\n",
      "\tAccuracy: 0.71875\n",
      "\tMicro-F1 Score: 0.71875\n",
      "\tMacro-F1 Score: 0.708502024291498\n",
      "Aspect_5:\n",
      "\tHamming Loss: 0.1875\n",
      "\tAccuracy: 0.8125\n",
      "\tMicro-F1 Score: 0.8125\n",
      "\tMacro-F1 Score: 0.5714285714285714\n",
      "Metrics Results for Complaint:\n",
      "Complaint_1:\n",
      "\tHamming Loss: 0.0625\n",
      "\tAccuracy: 0.9375\n",
      "\tMicro-F1 Score: 0.9375\n",
      "\tMacro-F1 Score: 0.4838709677419355\n",
      "Complaint_2:\n",
      "\tHamming Loss: 0.09375\n",
      "\tAccuracy: 0.90625\n",
      "\tMicro-F1 Score: 0.90625\n",
      "\tMacro-F1 Score: 0.6\n",
      "Complaint_3:\n",
      "\tHamming Loss: 0.0\n",
      "\tAccuracy: 1.0\n",
      "\tMicro-F1 Score: 1.0\n",
      "\tMacro-F1 Score: 1.0\n",
      "Complaint_4:\n",
      "\tHamming Loss: 0.265625\n",
      "\tAccuracy: 0.734375\n",
      "\tMicro-F1 Score: 0.734375\n",
      "\tMacro-F1 Score: 0.5157988429016467\n",
      "Complaint_5:\n",
      "\tHamming Loss: 0.15625\n",
      "\tAccuracy: 0.84375\n",
      "\tMicro-F1 Score: 0.84375\n",
      "\tMacro-F1 Score: 0.5989974937343359\n"
     ]
    }
   ],
   "source": [
    "def calculate_metrics(df):\n",
    "    # Initialize dictionaries to store results\n",
    "    metrics_results_aspects = {}\n",
    "    metrics_results_complaint = {}\n",
    "\n",
    "    # Calculate metrics for Aspects columns\n",
    "    for i in range(1, 6):\n",
    "        y_true_aspects = df[f'Aspects real_{i}'].values\n",
    "        y_pred_aspects = df[f'Aspects pred_{i}'].values\n",
    "        \n",
    "        hamming_loss_aspect = hamming_loss(y_true_aspects, y_pred_aspects)\n",
    "        micro_f1_aspect = f1_score(y_true_aspects, y_pred_aspects, average='micro')\n",
    "        macro_f1_aspect = f1_score(y_true_aspects, y_pred_aspects, average='macro')\n",
    "        \n",
    "        metrics_results_aspects[f'Aspect_{i}'] = {\n",
    "            'Hamming Loss': hamming_loss_aspect,\n",
    "            'Accuracy': accuracy_score(y_true_aspects, y_pred_aspects),\n",
    "            #'Zero-One Loss': zero_one_loss(y_true_aspects, y_pred_aspects),\n",
    "            'Micro-F1 Score': micro_f1_aspect,\n",
    "            'Macro-F1 Score': macro_f1_aspect\n",
    "        }\n",
    "\n",
    "    # Calculate metrics for Complaint columns\n",
    "    for i in range(1, 6):\n",
    "        y_true_complaint = df[f'Complaint real_{i}'].values\n",
    "        y_pred_complaint = df[f'Complaint pred_{i}'].values\n",
    "        \n",
    "        hamming_loss_complaint = hamming_loss(y_true_complaint, y_pred_complaint)\n",
    "        micro_f1_complaint = f1_score(y_true_complaint, y_pred_complaint, average='micro')\n",
    "        macro_f1_complaint = f1_score(y_true_complaint, y_pred_complaint, average='macro')\n",
    "        \n",
    "        metrics_results_complaint[f'Complaint_{i}'] = {\n",
    "            'Hamming Loss': hamming_loss_complaint,\n",
    "            'Accuracy': accuracy_score(y_true_complaint, y_pred_complaint),\n",
    "            #'Zero-One Loss': zero_one_loss(y_true_complaint, y_pred_complaint),\n",
    "            'Micro-F1 Score': micro_f1_complaint,\n",
    "            'Macro-F1 Score': macro_f1_complaint\n",
    "        }\n",
    "\n",
    "    return metrics_results_aspects, metrics_results_complaint\n",
    "\n",
    "\n",
    "\n",
    "# Print results for Aspects and Complaint\n",
    "def print_metrics(metrics_results, title):\n",
    "    print(f\"Metrics Results for {title}:\")\n",
    "    for key, metrics in metrics_results.items():\n",
    "        print(f\"{key}:\")\n",
    "        for metric_name, value in metrics.items():\n",
    "            print(f\"\\t{metric_name}: {value}\")\n",
    "\n",
    "# Example usage:\n",
    "metrics_results_aspects, metrics_results_complaint = calculate_metrics(df)\n",
    "# Example printing:\n",
    "print_metrics(metrics_results_aspects, \"Aspects\")\n",
    "print_metrics(metrics_results_complaint, \"Complaint\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
